{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXc5ZUaoGrHekdfo4ZBGsQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Poorya0071/NLP_TensorFlow/blob/main/NLP_oversampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "us9jarKPq3pW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_json('Musical_Instruments_5.json',lines=True)\n",
        "\n",
        "X = raw_data['reviewText'] + \"\" + raw_data['summary']\n",
        "raw_data['overall'] = raw_data['overall'].map({1:0,2:0,3:0,4:1,5:1})\n",
        "print(raw_data['overall'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJWDXtZMq51e",
        "outputId": "d291e875-70fa-4a93-ea2f-5480e704e287"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    9022\n",
            "0    1239\n",
            "Name: overall, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data[\"text\"] = X\n",
        "data = raw_data.sample(frac=1, random_state=42).reset_index()\n",
        "data.drop('index', axis = 1, inplace = True)\n",
        "X = data['text']\n",
        "y = data['overall']\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY8yMiAJq93i",
        "outputId": "f760360a-144e-46c4-c1f2-3b57cd8c5771"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        I've been using these on my acoustic guitars (...\n",
            "1        Sounds like a great concept and they seem well...\n",
            "2        I recently ordered a wide variety of picks to ...\n",
            "3        I have two of these stands, the electric guita...\n",
            "4        This guitar sounds awesome and stays in tune v...\n",
            "                               ...                        \n",
            "10256    A year ago, I wrote a lengthy comparison of th...\n",
            "10257    Okay well I lied in subject line, bad singers ...\n",
            "10258    This mic is strong, reliable and produces the ...\n",
            "10259    I'm an Irish-style DADGAD guitarist.  These pi...\n",
            "10260    This is a great little amp especially for the ...\n",
            "Name: text, Length: 10261, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(X,\n",
        "                                                                            y,\n",
        "                                                                            test_size=0.2, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42)"
      ],
      "metadata": {
        "id": "V9zvQvPdrCRy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(\n",
        "    sampling_strategy='not majority', # samples all but majority class\n",
        "    random_state=0,  # for reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "PeaMgEf6rD05"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_res, y_res = ros.fit_resample(train_sentences.to_numpy().reshape(-1, 1), train_labels)\n",
        "print(y_res.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALNgtZoqrFYa",
        "outputId": "d7f15564-0e1a-4a17-d511-2be76b9c4255"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    7213\n",
            "0    7213\n",
            "Name: overall, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df = pd.DataFrame()\n",
        "\n"
      ],
      "metadata": {
        "id": "es6oUAaRrGna"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(X_res.squeeze())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwVOnpK1rmmG",
        "outputId": "e2eaf163-2ba4-4894-8fac-bd4ec008d241"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        I like this product. The screen is big and eas...\n",
              "1        I wanted a guitar I could travel with, somethi...\n",
              "2        i got pink cause nobody would steal it, and we...\n",
              "3        This clamp on pair of miniature lamps does an ...\n",
              "4        This string set offers typical D'Addario quali...\n",
              "                               ...                        \n",
              "14421    I bought this capo thinking it would look slic...\n",
              "14422    Before I purchased the FBV I scoured the web t...\n",
              "14423    These have the correct thickness and texture t...\n",
              "14424    I just got these in and I have to say, very di...\n",
              "14425    The strap locks do work... But they are kind o...\n",
              "Length: 14426, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text'] = X_res.squeeze()"
      ],
      "metadata": {
        "id": "dBQE87vJradl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['target'] = y_res"
      ],
      "metadata": {
        "id": "O5HAPgMLrjAd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ysu3JJL6r6Tz",
        "outputId": "5b192359-06cb-43c2-d27d-052299f0b9e5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target\n",
              "0  I like this product. The screen is big and eas...       1\n",
              "1  I wanted a guitar I could travel with, somethi...       1\n",
              "2  i got pink cause nobody would steal it, and we...       1\n",
              "3  This clamp on pair of miniature lamps does an ...       1\n",
              "4  This string set offers typical D'Addario quali...       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5173bed8-06eb-4034-a8cb-886fa28c48d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I like this product. The screen is big and eas...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I wanted a guitar I could travel with, somethi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i got pink cause nobody would steal it, and we...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This clamp on pair of miniature lamps does an ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This string set offers typical D'Addario quali...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5173bed8-06eb-4034-a8cb-886fa28c48d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5173bed8-06eb-4034-a8cb-886fa28c48d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5173bed8-06eb-4034-a8cb-886fa28c48d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe27SKixsVyW",
        "outputId": "d458654c-f996-4ce7-83f7-56818324238b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2507    Like it better than the other tuner I bought, ...\n",
              "5159    I actually wasn't aware of this gauge of strin...\n",
              "932     I haven't used this yet, but it seems solid an...\n",
              "1190    Shipped in time. Just what I have expected. lo...\n",
              "2619    Works just fine. Except the little knob that's...\n",
              "                              ...                        \n",
              "400     I picked up a couple of these straps, one for ...\n",
              "2956    I purchased several of thes Fender Mini stands...\n",
              "3614    In our acoustic guitar band, I often play intr...\n",
              "3501    I needed a cheap mic stand that didn't break t...\n",
              "6671    Simple. Effective.  Just what I wanted.  Seems...\n",
              "Name: text, Length: 2053, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 40000\n",
        "embedding_dim = 128\n",
        "max_length = 94\n",
        "trunc_type='post'\n",
        "pad_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_df['text'])\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(train_df['text'])\n",
        "training_padded = pad_sequences(training_sequences,maxlen=max_length,\n",
        "                                truncating=trunc_type, padding=pad_type)\n",
        "\n",
        "validation_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
        "validation_padded = pad_sequences(validation_sequences,maxlen=max_length)\n",
        "\n",
        "training_labels_final = np.array(train_df['target'])\n",
        "validation_labels_final = np.array(val_labels)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Fit the model\n",
        "num_epochs = 20\n",
        "history = model.fit(training_padded, training_labels_final, epochs=num_epochs,\n",
        "                    validation_data=(validation_padded, validation_labels_final))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROtL_L4Ar77-",
        "outputId": "cd6c4085-14e0-46d2-973c-a35376f289e6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 94, 128)           5120000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,120,129\n",
            "Trainable params: 5,120,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "451/451 [==============================] - 38s 83ms/step - loss: 0.5902 - accuracy: 0.6984 - val_loss: 0.4805 - val_accuracy: 0.8110\n",
            "Epoch 2/20\n",
            "451/451 [==============================] - 34s 76ms/step - loss: 0.3577 - accuracy: 0.8737 - val_loss: 0.3533 - val_accuracy: 0.8651\n",
            "Epoch 3/20\n",
            "451/451 [==============================] - 32s 70ms/step - loss: 0.2362 - accuracy: 0.9260 - val_loss: 0.3092 - val_accuracy: 0.8734\n",
            "Epoch 4/20\n",
            "451/451 [==============================] - 31s 69ms/step - loss: 0.1664 - accuracy: 0.9537 - val_loss: 0.2911 - val_accuracy: 0.8782\n",
            "Epoch 5/20\n",
            "451/451 [==============================] - 33s 73ms/step - loss: 0.1203 - accuracy: 0.9713 - val_loss: 0.2985 - val_accuracy: 0.8797\n",
            "Epoch 6/20\n",
            "451/451 [==============================] - 37s 82ms/step - loss: 0.0886 - accuracy: 0.9806 - val_loss: 0.2963 - val_accuracy: 0.8953\n",
            "Epoch 7/20\n",
            "451/451 [==============================] - 37s 83ms/step - loss: 0.0670 - accuracy: 0.9873 - val_loss: 0.3221 - val_accuracy: 0.8904\n",
            "Epoch 8/20\n",
            "451/451 [==============================] - 43s 94ms/step - loss: 0.0509 - accuracy: 0.9914 - val_loss: 0.3388 - val_accuracy: 0.8943\n",
            "Epoch 9/20\n",
            "451/451 [==============================] - 30s 65ms/step - loss: 0.0391 - accuracy: 0.9941 - val_loss: 0.3607 - val_accuracy: 0.8919\n",
            "Epoch 10/20\n",
            "451/451 [==============================] - 28s 62ms/step - loss: 0.0301 - accuracy: 0.9965 - val_loss: 0.3829 - val_accuracy: 0.8894\n",
            "Epoch 11/20\n",
            "451/451 [==============================] - 33s 74ms/step - loss: 0.0233 - accuracy: 0.9975 - val_loss: 0.4091 - val_accuracy: 0.8836\n",
            "Epoch 12/20\n",
            "451/451 [==============================] - 29s 65ms/step - loss: 0.0179 - accuracy: 0.9983 - val_loss: 0.4350 - val_accuracy: 0.8904\n",
            "Epoch 13/20\n",
            "451/451 [==============================] - 36s 80ms/step - loss: 0.0137 - accuracy: 0.9985 - val_loss: 0.4559 - val_accuracy: 0.8860\n",
            "Epoch 14/20\n",
            "451/451 [==============================] - 31s 68ms/step - loss: 0.0106 - accuracy: 0.9992 - val_loss: 0.4806 - val_accuracy: 0.8855\n",
            "Epoch 15/20\n",
            "451/451 [==============================] - 31s 69ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.5093 - val_accuracy: 0.8885\n",
            "Epoch 16/20\n",
            "451/451 [==============================] - 34s 75ms/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.5324 - val_accuracy: 0.8865\n",
            "Epoch 17/20\n",
            "451/451 [==============================] - 31s 68ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.5641 - val_accuracy: 0.8885\n",
            "Epoch 18/20\n",
            "451/451 [==============================] - 32s 71ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.5858 - val_accuracy: 0.8841\n",
            "Epoch 19/20\n",
            "451/451 [==============================] - 33s 72ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6140 - val_accuracy: 0.8850\n",
            "Epoch 20/20\n",
            "451/451 [==============================] - 32s 71ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6374 - val_accuracy: 0.8855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "data_math = pd.read_csv('raw_text.csv')\n",
        "print(data_math.head())\n",
        "print(data_math.label.value_counts())\n",
        "X = data_math['text']\n",
        "y = data_math['label']\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(X,\n",
        "                                                                            y,\n",
        "                                                                            test_size=0.2, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42)\n",
        "print(train_labels.value_counts())\n",
        "\n",
        "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
        "sampling_strategy={'Linear Algebra':126,'Probability':104, 'CS':100, 'Diff. Eq.':100, 'Algorithms':100, 'Statistics':100, 'Calculus':100, 'Data Structures': 100, 'AI':100, 'Math for Eng.': 100, 'NLP':100 }\n",
        "oversample = RandomOverSampler(sampling_strategy=sampling_strategy)\n",
        "X_train,y_train= oversample.fit_resample(train_sentences.to_numpy().reshape(-1,1),train_labels)\n",
        "\n",
        "print(y_train.value_counts())\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(y_train.to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_labels.to_numpy())\n",
        "\n",
        "\n",
        "print(train_labels_encoded)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "print(class_names)\n",
        "print(num_classes)\n",
        "\n",
        "train_text = pd.Series(X_train.squeeze())\n",
        "\n",
        "vocab_size = 40000\n",
        "embedding_dim = 128\n",
        "max_length = 94\n",
        "trunc_type='post'\n",
        "pad_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(train_text)\n",
        "training_padded = pad_sequences(training_sequences,maxlen=max_length,\n",
        "                                truncating=trunc_type, padding=pad_type)\n",
        "\n",
        "validation_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
        "validation_padded = pad_sequences(validation_sequences,maxlen=max_length)\n",
        "\n",
        "# training_labels_final = np.array(y_res)\n",
        "# validation_labels_final = np.array(val_labels)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Fit the model\n",
        "num_epochs = 20\n",
        "history = model.fit(training_padded, train_labels_encoded, epochs=num_epochs,\n",
        "                    validation_data=(validation_padded, val_labels_encoded))"
      ],
      "metadata": {
        "id": "HLFONXjgsanA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}